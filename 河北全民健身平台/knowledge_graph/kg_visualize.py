#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
FPSçŸ¥è¯†å›¾è°±å¯è§†åŒ–è„šæœ¬
ç”ŸæˆçŸ¥è¯†å›¾è°±çš„ç»Ÿè®¡å›¾è¡¨å’Œç½‘ç»œå›¾
"""

import json
import sys
from pathlib import Path
from collections import defaultdict, Counter
from loguru import logger

# é…ç½®æ—¥å¿—
logger.remove()
logger.add(sys.stderr, level="INFO")


def load_knowledge_graph(kg_file: str) -> dict:
    """åŠ è½½çŸ¥è¯†å›¾è°±"""
    with open(kg_file, 'r', encoding='utf-8') as f:
        return json.load(f)


def generate_statistics_report(kg_data: dict):
    """ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š"""
    logger.info("=" * 80)
    logger.info("æ²³åŒ—çœå…¨æ°‘å¥èº«å…¬å…±æœåŠ¡çŸ¥è¯†å›¾è°± - ç»Ÿè®¡æŠ¥å‘Š")
    logger.info("=" * 80)
    
    metadata = kg_data['metadata']
    entities = kg_data['entities']
    relations = kg_data['relations']
    stats = kg_data['statistics']
    
    # åŸºæœ¬ä¿¡æ¯
    logger.info(f"\nğŸ“Š åŸºæœ¬ä¿¡æ¯")
    logger.info(f"  åç§°: {metadata['name']}")
    logger.info(f"  åˆ›å»ºæ—¶é—´: {metadata['created_at']}")
    logger.info(f"  æ•°æ®æ¥æº: fitness_facilities_data.json")
    
    # ç»´åº¦ä¿¡æ¯
    logger.info(f"\nğŸ¯ çŸ¥è¯†ç»´åº¦ ({len(metadata['dimensions'])}ä¸ª)")
    for i, dim in enumerate(metadata['dimensions'], 1):
        logger.info(f"  {i}. {dim}")
    
    # å®ä½“ç»Ÿè®¡
    logger.info(f"\nğŸ“¦ å®ä½“ç»Ÿè®¡")
    logger.info(f"  æ€»å®ä½“æ•°: {stats['total_entities']}")
    for entity_type, count in stats['entities'].items():
        percentage = (count / stats['total_entities'] * 100) if stats['total_entities'] > 0 else 0
        bar = "â–ˆ" * int(percentage / 5)
        logger.info(f"  {entity_type:12s}: {count:4d} ({percentage:5.1f}%) {bar}")
    
    # å…³ç³»ç»Ÿè®¡
    logger.info(f"\nğŸ”— å…³ç³»ç»Ÿè®¡")
    logger.info(f"  æ€»å…³ç³»æ•°: {stats['total_relations']}")
    logger.info(f"  å…³ç³»ç±»å‹æ•°: {stats['relation_types']}")
    
    # ç»Ÿè®¡å„ç±»å…³ç³»æ•°é‡
    relation_types = Counter(r['predicate'] for r in relations)
    logger.info(f"\n  å…³ç³»ç±»å‹åˆ†å¸ƒ:")
    for rel_type, count in relation_types.most_common():
        percentage = (count / stats['total_relations'] * 100) if stats['total_relations'] > 0 else 0
        bar = "â–ˆ" * int(percentage / 5)
        logger.info(f"    {rel_type:12s}: {count:4d} ({percentage:5.1f}%) {bar}")


def analyze_facilities(kg_data: dict):
    """åˆ†æè®¾æ–½æ•°æ®"""
    logger.info("\n" + "=" * 80)
    logger.info("è®¾æ–½ç»´åº¦åˆ†æ")
    logger.info("=" * 80)
    
    facilities = kg_data['entities']['Facility']
    
    # æŒ‰ç±»å‹ç»Ÿè®¡
    type_count = Counter(f.get('type', 'æœªçŸ¥') for f in facilities.values())
    logger.info(f"\nè®¾æ–½ç±»å‹åˆ†å¸ƒ (å…±{len(facilities)}ä¸ª):")
    for ftype, count in type_count.most_common():
        percentage = (count / len(facilities) * 100)
        logger.info(f"  {ftype:12s}: {count:3d} ({percentage:5.1f}%)")
    
    # é¢ç§¯ç»Ÿè®¡
    total_area = sum(f.get('site_area', 0) for f in facilities.values())
    avg_area = total_area / len(facilities) if facilities else 0
    logger.info(f"\nåœºåœ°é¢ç§¯ç»Ÿè®¡:")
    logger.info(f"  æ€»é¢ç§¯: {total_area:,.0f} å¹³æ–¹ç±³")
    logger.info(f"  å¹³å‡é¢ç§¯: {avg_area:,.0f} å¹³æ–¹ç±³/ä¸ª")
    
    # å®¢æµç»Ÿè®¡
    total_visitors = sum(f.get('daily_visitors', 0) for f in facilities.values())
    avg_visitors = total_visitors / len(facilities) if facilities else 0
    logger.info(f"\nå®¢æµç»Ÿè®¡:")
    logger.info(f"  æ€»æ—¥å®¢æµ: {total_visitors:,} äººæ¬¡")
    logger.info(f"  å¹³å‡æ—¥å®¢æµ: {avg_visitors:,.0f} äººæ¬¡/ä¸ª")


def analyze_areas(kg_data: dict):
    """åˆ†æåŒºåŸŸæ•°æ®"""
    logger.info("\n" + "=" * 80)
    logger.info("åŒºåŸŸç»´åº¦åˆ†æ")
    logger.info("=" * 80)
    
    areas = kg_data['entities']['Area']
    relations = kg_data['relations']
    
    # ç»Ÿè®¡å„åŸå¸‚çš„è®¾æ–½æ•°é‡
    city_facilities = defaultdict(int)
    for rel in relations:
        if rel['predicate'] == 'ä½äº':
            # è·å–åŸå¸‚åç§°
            area_id = rel['object']
            if area_id in areas:
                area = areas[area_id]
                if area.get('level') == 'å¸‚çº§':
                    city_facilities[area['name']] += 1
    
    logger.info(f"\nå„åŸå¸‚è®¾æ–½æ•°é‡æ’å:")
    for i, (city, count) in enumerate(sorted(city_facilities.items(), key=lambda x: x[1], reverse=True), 1):
        bar = "â–ˆ" * (count // 2)
        logger.info(f"  {i:2d}. {city:12s}: {count:3d} ä¸ª {bar}")


def analyze_time_dimension(kg_data: dict):
    """åˆ†ææ—¶é—´ç»´åº¦"""
    logger.info("\n" + "=" * 80)
    logger.info("æ—¶é—´ç»´åº¦åˆ†æ")
    logger.info("=" * 80)
    
    facilities = kg_data['entities']['Facility']
    
    # æŒ‰å¹´ä»£ç»Ÿè®¡
    decade_count = defaultdict(int)
    for f in facilities.values():
        year = f.get('build_year', 0)
        if year > 0:
            decade = (year // 10) * 10
            decade_count[decade] += 1
    
    logger.info(f"\nå„å¹´ä»£è®¾æ–½å»ºè®¾æ•°é‡:")
    for decade in sorted(decade_count.keys()):
        count = decade_count[decade]
        bar = "â–ˆ" * (count // 3)
        logger.info(f"  {decade}å¹´ä»£: {count:3d} ä¸ª {bar}")
    
    # æœ€æ–°è®¾æ–½
    recent_facilities = sorted(
        [(f.get('name', ''), f.get('build_year', 0)) for f in facilities.values()],
        key=lambda x: x[1],
        reverse=True
    )[:5]
    
    logger.info(f"\næœ€æ–°å»ºæˆçš„è®¾æ–½:")
    for name, year in recent_facilities:
        if year > 0:
            logger.info(f"  {year}å¹´: {name}")


def analyze_indicators(kg_data: dict):
    """åˆ†ææŒ‡æ ‡ç»´åº¦"""
    logger.info("\n" + "=" * 80)
    logger.info("æŒ‡æ ‡ç»´åº¦åˆ†æ")
    logger.info("=" * 80)
    
    indicators = kg_data['entities']['Indicator']
    
    # äººå‡åœºåœ°é¢ç§¯æŒ‡æ ‡
    per_capita_indicators = [
        ind for ind in indicators.values()
        if ind.get('indicator_type') == 'äººå‡ä½“è‚²åœºåœ°é¢ç§¯'
    ]
    
    if per_capita_indicators:
        logger.info(f"\näººå‡ä½“è‚²åœºåœ°é¢ç§¯æŒ‡æ ‡ (å‡è®¾äººå£100ä¸‡):")
        sorted_indicators = sorted(per_capita_indicators, key=lambda x: x.get('value', 0), reverse=True)
        for ind in sorted_indicators:
            city = ind.get('area', 'æœªçŸ¥')
            value = ind.get('value', 0)
            bar = "â–ˆ" * int(value * 50)
            logger.info(f"  {city:12s}: {value:.2f} å¹³æ–¹ç±³/äºº {bar}")


def generate_network_structure(kg_data: dict):
    """ç”Ÿæˆç½‘ç»œç»“æ„æè¿°"""
    logger.info("\n" + "=" * 80)
    logger.info("çŸ¥è¯†å›¾è°±ç½‘ç»œç»“æ„")
    logger.info("=" * 80)
    
    stats = kg_data['statistics']
    relations = kg_data['relations']
    
    # è®¡ç®—ç½‘ç»œå¯†åº¦
    total_entities = stats['total_entities']
    total_relations = stats['total_relations']
    
    # æœ€å¤§å¯èƒ½å…³ç³»æ•° = n * (n-1) / 2
    max_relations = total_entities * (total_entities - 1) / 2
    density = (total_relations / max_relations * 100) if max_relations > 0 else 0
    
    logger.info(f"\nç½‘ç»œç‰¹å¾:")
    logger.info(f"  èŠ‚ç‚¹æ•°: {total_entities}")
    logger.info(f"  è¾¹æ•°: {total_relations}")
    logger.info(f"  ç½‘ç»œå¯†åº¦: {density:.4f}%")
    logger.info(f"  å¹³å‡åº¦: {total_relations * 2 / total_entities:.2f}")
    
    # ç»Ÿè®¡å‡ºåº¦å’Œå…¥åº¦
    out_degree = defaultdict(int)
    in_degree = defaultdict(int)
    
    for rel in relations:
        out_degree[rel['subject']] += 1
        in_degree[rel['object']] += 1
    
    # æ‰¾å‡ºåº¦æœ€é«˜çš„èŠ‚ç‚¹
    if out_degree:
        max_out = max(out_degree.items(), key=lambda x: x[1])
        logger.info(f"  æœ€å¤§å‡ºåº¦: {max_out[1]} ({max_out[0]})")
    
    if in_degree:
        max_in = max(in_degree.items(), key=lambda x: x[1])
        logger.info(f"  æœ€å¤§å…¥åº¦: {max_in[1]} ({max_in[0]})")


def export_summary(kg_data: dict, output_file: str):
    """å¯¼å‡ºæ‘˜è¦ä¿¡æ¯"""
    summary = {
        'name': kg_data['metadata']['name'],
        'created_at': kg_data['metadata']['created_at'],
        'dimensions': kg_data['metadata']['dimensions'],
        'statistics': kg_data['statistics'],
        'top_cities': [],
        'facility_types': {},
        'time_periods': {}
    }
    
    # åŸå¸‚æ’å
    areas = kg_data['entities']['Area']
    relations = kg_data['relations']
    
    city_facilities = defaultdict(int)
    for rel in relations:
        if rel['predicate'] == 'ä½äº':
            area_id = rel['object']
            if area_id in areas:
                area = areas[area_id]
                if area.get('level') == 'å¸‚çº§':
                    city_facilities[area['name']] += 1
    
    summary['top_cities'] = [
        {'city': city, 'count': count}
        for city, count in sorted(city_facilities.items(), key=lambda x: x[1], reverse=True)[:10]
    ]
    
    # è®¾æ–½ç±»å‹
    facilities = kg_data['entities']['Facility']
    type_count = Counter(f.get('type', 'æœªçŸ¥') for f in facilities.values())
    summary['facility_types'] = dict(type_count)
    
    # ä¿å­˜
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(summary, f, ensure_ascii=False, indent=2)
    
    logger.info(f"\nâœ… æ‘˜è¦å·²å¯¼å‡ºåˆ°: {output_file}")


def main():
    """ä¸»å‡½æ•°"""
    logger.info("=" * 80)
    logger.info("FPSçŸ¥è¯†å›¾è°±å¯è§†åŒ–åˆ†æ")
    logger.info("=" * 80)
    
    # åŠ è½½çŸ¥è¯†å›¾è°±
    kg_data = load_knowledge_graph('fps_knowledge_graph.json')
    
    # ç”Ÿæˆå„ç±»åˆ†æ
    generate_statistics_report(kg_data)
    analyze_facilities(kg_data)
    analyze_areas(kg_data)
    analyze_time_dimension(kg_data)
    analyze_indicators(kg_data)
    generate_network_structure(kg_data)
    
    # å¯¼å‡ºæ‘˜è¦
    export_summary(kg_data, 'fps_kg_summary.json')
    
    logger.info("\n" + "=" * 80)
    logger.info("ğŸ‰ åˆ†æå®Œæˆ!")
    logger.info("=" * 80)
    logger.info("\nè¾“å‡ºæ–‡ä»¶:")
    logger.info("  - fps_kg_summary.json (æ‘˜è¦ä¿¡æ¯)")
    logger.info("\nå¯è§†åŒ–å»ºè®®:")
    logger.info("  - ä½¿ç”¨Protegeæ‰“å¼€ fps_ontology.owl æŸ¥çœ‹æœ¬ä½“ç»“æ„")
    logger.info("  - ä½¿ç”¨Neo4jå¯¼å…¥æ•°æ®è¿›è¡Œå›¾å¯è§†åŒ–")
    logger.info("  - ä½¿ç”¨Gephiè¿›è¡Œç½‘ç»œåˆ†æ")


if __name__ == "__main__":
    main()
